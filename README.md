# DE_Capstone

## Overview
In this repo, you will find demonstration of ETL from a credit card dataset using pyspark sql, performing tranformations on those datasets, and loading it into a MySql database.
    -Requirements:
    -You will need to have python installed, 3.10 and above.
    -Spark installation
        -Java installation required, Java 8 and above. Download available: https://www.oracle.com/java/technologies/downloads/#java8-windows  
        -Spark, download available: https://spark.apache.org/downloads.html  
        -Edit and set environmental variables  
    Python installation: https://www.python.org/  
    MySql Workbench installation: https://dev.mysql.com/downloads/workbench/   

## Techonolgies used

-Pyspark  
-Python  
-Python SQL library  
-RDBMS(MySql)  
-API  
-pandas  
-Matplotlib  
-seaborn  

Extraction of the information from the CC Dataset using pyspark, once read. Load the data into the RDBMS. Python is used to create an interactive console program for users to get information on the information loaded in the RDBMS. An API request is made to a loan application json file, which is then used to create visualizations    

Data Visualizations for customers are provided to plot percetage of appliations for self-employe applicants, rejections for married males, three months with the largest transactions, and the highest total dollar amount for healthcare transactions.  